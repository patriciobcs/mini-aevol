{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Aevol OpenMP Optimization Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to analyze the results of the Mini Aevol OpenMP optimization. \n",
    "\n",
    "Aevol is a digital genetics model: populations of digital organisms are subjected to a process of selection and variation, which creates a Darwinian dynamics. The simulation platform comes along with a set of tools for analysing phylogenies and measuring many characteristics of the organisms and populations along evolution.\n",
    "\n",
    "The results can be regenerated in the `experiments` folder by running the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make setup\n",
    "!make run all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 0 - No parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to increase the performance of a system, it is important to understand the bottlenecks of the system. This can be done by profiling the system. The profiling results are stored in the `experiments` folder. The following block will generate the profiling results of the mini aevol with parallelization level 0 (no parallelization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make prof L=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the following profiling results in the `Instruments` app (MacOS):\n",
    "\n",
    "![Level 0 Profiling](./resources/PL00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the program spend almost 70% of the time in the `run_step` function (total of all the calls). This makes senses due to it is the place where the mutations are happening. However, this also means that we can optimize the function using OpenMP to parellelize the operations that are executed over the individuals.\n",
    "\n",
    "The `run_step` function is called N times in the simulation. This means that we any optimization we do in the function, will be affecting the system N times. The `run_step` function is composed of:\n",
    "\n",
    "![Level 0 Profiling](./resources/PL01.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two possible approach to start optimizing the program:\n",
    "\n",
    "- Analyze the section in the same order they are in the previous image and start optimizing what is possible.\n",
    "- Analyze the sections with more than 1% of the total time and start optimizing what is possible in order of execution.\n",
    "\n",
    "We are going to choose the second approach for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1 - Parallelize the mutation of the individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw, in the previous section, that the `evaluate`, `prepare_mutation`, `selection` and `apply_mutations` functions are taking almost 40% of the total time. This functions are executed for each individual inside a sequential for loop. We can parallelize this loop to improve the performance of the program. If they still are consuming more than 1% of the total time, we can optimize them them. \n",
    "\n",
    "This is optimization done by adding the `#pragma omp parallel for` directive in first section of the `run_step` function:\n",
    "\n",
    "```c++\n",
    "#pragma omp parallel for shared(dna_mutator_array_) if (level_ > 0) num_threads(4)\n",
    "for (int indiv_id = 0; indiv_id < nb_indivs_; indiv_id++) {\n",
    "    selection(indiv_id);\n",
    "    prepare_mutation(indiv_id);\n",
    "\n",
    "    if (dna_mutator_array_[indiv_id]->hasMutate()) {\n",
    "        auto &mutant = internal_organisms_[indiv_id];\n",
    "        mutant->apply_mutations(dna_mutator_array_[indiv_id]->mutation_list_);\n",
    "        mutant->evaluate(target);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "We can start with a 4 threads parallelization due to it is a good number for the number of cores of the machine we are using. Later we're going to try different values to see how it affects the performance. The `if (level_ > 0)` is used to accumulate optimization on each level, this means that next levels will include this level.\n",
    "\n",
    "The following block will generate the profiling results of the mini aevol with parallelization level 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make prof L=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the following profiling results in the `Instruments` app (MacOS):\n",
    "\n",
    "![Level 0 Profiling](./resources/PL10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the execution time of `run_step` decreased radically from almost 70% to almost 30%. This means that we have a 2x improvement in the performance of the program. \n",
    "\n",
    "Now, the runtime of each function in the `run_step` function is the following:\n",
    "\n",
    "![Level 1 Profiling](./resources/PL11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2 - Parallelize the natural selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "// Search for the best\n",
    "struct Case { float value; int index; };    \n",
    "#pragma omp declare reduction(best : struct Case : omp_out = omp_in.value > omp_out.value ? omp_in : omp_out)\n",
    "\n",
    "struct Case best_fitness; \n",
    "best_fitness.value = prev_internal_organisms_[0]->fitness;\n",
    "best_fitness.index = 0;\n",
    "\n",
    "#pragma omp parallel for reduction(best:best_fitness) shared(prev_internal_organisms_, internal_organisms_) if (level_ > 1) num_threads(4)\n",
    "for (int indiv_id = 1; indiv_id < nb_indivs_; indiv_id++) {\n",
    "    if (prev_internal_organisms_[indiv_id]->fitness > best_fitness.value) {\n",
    "        best_fitness.index = indiv_id;\n",
    "        best_fitness.value = prev_internal_organisms_[indiv_id]->fitness;\n",
    "    }\n",
    "}\n",
    "best_indiv = prev_internal_organisms_[best_fitness.index];\n",
    "```\n",
    "\n",
    "![Level 2 Profiling](./resources/PL20.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
